{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vS6rHHOQrbp3"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers, activations, Input\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10_data(img_rows, img_cols):\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    x_train = x_train[0:2000, :, :, :]\n",
        "    y_train = y_train[0:2000]\n",
        "\n",
        "    x_test = x_test[0:500, :, :, :]\n",
        "    y_test = y_test[0:500]\n",
        "\n",
        "    x_train = np.array([cv2.resize(img, (img_rows, img_cols)) for img in x_train[:, :, :, :]])\n",
        "    x_test = np.array([cv2.resize(img, (img_rows, img_cols)) for img in x_test[:, :, :, :]])\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_cifar10_data(224, 224)\n",
        "img_input = Input(shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "LQvcNqLmrhm5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualUnit(layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = activations.get(activation)\n",
        "        self.main_layers = [layers.Conv2D(filters, (3, 3),\n",
        "             strides=strides, padding='same', use_bias=False),\n",
        "            layers.BatchNormalization(),\n",
        "            self.activation,\n",
        "            layers.Conv2D(filters, (3, 3), strides=1, padding='same', use_bias=False),\n",
        "            layers.BatchNormalization()]\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                layers.Conv2D(filters, (1, 1), strides=strides, padding = 'same', use_bias=False),\n",
        "                layers.BatchNormalization()]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "        return self.activation(Z + skip_Z)"
      ],
      "metadata": {
        "id": "A8rGgXd2rhpY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(layers.Conv2D(64, (7, 7), strides=(2, 2), input_shape=[224, 224, 3], padding='same',use_bias=False))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(3,3), strides=(2, 2), padding='same'))\n",
        "prev_filters = 64\n",
        "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    model.add(ResidualUnit(filters,strides=strides))\n",
        "    prev_filters = filters\n",
        "model.add(layers.GlobalAvgPool2D())\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "2RCEqgecrhro"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss = 'sparse_categorical_crossentropy',\n",
        "             metrics = ['accuracy'])\n",
        "model.fit(x_train,y_train,epochs=5,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN2P68wGrhuS",
        "outputId": "55c2b458-a3a7-438b-e88c-1320d992ae33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "16/63 [======>.......................] - ETA: 14:49 - loss: 3.8042 - accuracy: 0.1562"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "print('테스트 정확도 :', score[1])"
      ],
      "metadata": {
        "id": "_z78uc8hrhw4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}