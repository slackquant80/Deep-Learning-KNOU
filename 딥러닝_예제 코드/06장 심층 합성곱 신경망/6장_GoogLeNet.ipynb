{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9zas0z2cqZCV"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, concatenate, GlobalAveragePooling2D, AveragePooling2D, Flatten, Input, Dropout\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10_data(img_rows, img_cols):\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    x_train = x_train[0:2000, :, :, :]\n",
        "    y_train = y_train[0:2000]\n",
        "\n",
        "    x_test = x_test[0:500, :, :, :]\n",
        "    y_test = y_test[0:500]\n",
        "\n",
        "    x_train = np.array([cv2.resize(img, (img_rows, img_cols)) for img in x_train[:, :, :, :]])\n",
        "    x_test = np.array([cv2.resize(img, (img_rows, img_cols)) for img in x_test[:, :, :, :]])\n",
        "\n",
        "    y_train = np_utils.to_categorical(y_train, 10)\n",
        "    y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_cifar10_data(224, 224)\n",
        "img_input = Input(shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "0zNrboXNqe6Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj, name=None, kernel_init='glorot_uniform', bias_init='zeros'):\n",
        "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_3x3_reduce = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3_reduce)\n",
        "    conv_5x5_reduce = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5_reduce)\n",
        "    max_pool = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(max_pool)\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
        "    return output"
      ],
      "metadata": {
        "id": "JjpwosjBqe84"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decay(epoch, steps=100):\n",
        "    initial_lrate = 0.01\n",
        "    drop = 0.96\n",
        "    epoch_drop = 8\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epoch_drop))\n",
        "    return lrate"
      ],
      "metadata": {
        "id": "fyfxNSnfqe_Z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_init = keras.initializers.glorot_uniform()\n",
        "bias_init = keras.initializers.Constant(value=0.2)\n",
        "input_layer = Input(shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "CyKAlFeOqfBg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시작 부분\n",
        "x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2', kernel_initializer=kernel_init,\n",
        "bias_initializer=bias_init)(input_layer)\n",
        "x = MaxPool2D((3, 3), strides=(2, 2), name='max_pool_1_3x3/2', padding='same')(x)\n",
        "\n",
        "x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2_3x3/1', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "x = MaxPool2D((3, 3), strides=(2, 2), name='max_pool_2_3x3/2', padding='same')(x)\n",
        "\n",
        "#중간 부분\n",
        "x = inception_module(x, 64, 96, 128, 16, 32, 32, name='inception_3a', kernel_init=kernel_init, bias_init=bias_init)\n",
        "x = inception_module(x, 128, 128, 192, 32, 96, 64, name='inception_3b', kernel_init=kernel_init, bias_init=bias_init)\n",
        "x = MaxPool2D((3, 3), strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x, 192, 96, 208, 16, 48, 64, name='inception_4a')\n",
        "\n",
        "#중간 부분의 첫 번째 보조 분류기\n",
        "x1 = AveragePooling2D((5, 5), strides=3, name='avg_pool_aux_1')(x)\n",
        "x1 = Conv2D(128, (1, 1), padding='same', activation='relu', name='conv_aux_1')(x1)\n",
        "x1 = Flatten()(x1)\n",
        "x1 = Dense(1024, activation='relu', name='dense_aux_1')(x1)\n",
        "x1 = Dense(10, activation='softmax', name='aux_output_1')(x1)\n",
        "\n",
        "x = inception_module(x, 160, 112, 224, 24, 64, 64, name='inception_4b', kernel_init=kernel_init, bias_init=bias_init)\n",
        "x = inception_module(x, 128, 128, 256, 24, 64, 64, name='inception_4c', kernel_init=kernel_init, bias_init=bias_init)\n",
        "x = inception_module(x, 112, 144, 288, 32, 64, 64, name='inception_4d', kernel_init=kernel_init, bias_init=bias_init)\n",
        "\n",
        "#중간 부분의 두 번째 보조 분류기\n",
        "x2 = AveragePooling2D((5, 5), strides=3, name='avg_pool_aux_2')(x)\n",
        "x2 = Conv2D(128, (1, 1), padding='same', activation='relu', name='conv_aux_2')(x2)\n",
        "x2 = Flatten()(x2)\n",
        "x2 = Dense(1024, activation='relu', name='dense_aux_2')(x2)\n",
        "x2 = Dense(10, activation='softmax', name='aux_output_2')(x2)\n",
        "\n",
        "x = inception_module(x, 256, 160, 320, 32, 128, 128, name='inception_4e', kernel_init=kernel_init, bias_init=bias_init)\n",
        "x = MaxPool2D((3, 3), strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x, 256, 160, 320, 32, 128, 128, name='inception_5a', kernel_init=kernel_init, bias_init=bias_init)\n",
        "x = inception_module(x, 384, 192, 384, 48, 128, 128, name='inception_5b', kernel_init=kernel_init, bias_init=bias_init)\n",
        "\n",
        "# 끝 부분\n",
        "x = GlobalAveragePooling2D(name='global_avg_pool_5_3x3/1')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(10, activation='softmax', name='output')(x)\n",
        "\n",
        "# 모델 저장\n",
        "model = Model(input_layer, [x, x1, x2], name='GoogLeNet')"
      ],
      "metadata": {
        "id": "ZLHZWXSlqfDw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGD(lr=0.01, momentum=0.9, nesterov=False)\n",
        "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
        "model.compile(loss=['categorical_crossentropy',\n",
        "'categorical_crossentropy', 'categorical_crossentropy'],\n",
        "            loss_weights=[1, 0.3, 0.3], optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, [y_train, y_train, y_train], validation_data=(x_test, [y_test, y_test, y_test]),\n",
        "                  epochs=5, callbacks=[lr_sc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPsr0wpSqofA",
        "outputId": "7a21cb87-9999-433f-eeec-808f2635bd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/5\n",
            "54/63 [========================>.....] - ETA: 1:22 - loss: 3.8886 - output_loss: 2.4987 - aux_output_1_loss: 2.3122 - aux_output_2_loss: 2.3207 - output_accuracy: 0.0966 - aux_output_1_accuracy: 0.1117 - aux_output_2_accuracy: 0.0955"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "print('테스트 정확도 :', score[1])"
      ],
      "metadata": {
        "id": "X2pm5CTrqfF4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}